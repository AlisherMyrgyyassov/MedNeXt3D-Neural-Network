{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel size k x k x k\n",
    "# 1. Depthwise Convolution with kernel size k × k × k\n",
    "# 2. Normalization, with C output channels\n",
    "#       We use channel-wise GroupNorm for stability with small\n",
    "#       batches, instead of the original LayerNorm\n",
    "class DepthwiseConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, padding=0, bias=False):\n",
    "        super(DepthwiseConv3d, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv3d(in_channels, in_channels, \n",
    "                                        kernel_size=kernel_size, padding=padding, \n",
    "                                        groups=in_channels, bias=bias)\n",
    "        self.norm = nn.GroupNorm(num_groups=in_channels, num_channels=in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise_conv(x)\n",
    "        out = self.norm(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Expansion layer contains:\n",
    "# 1. An overcomplete Convolution Layer with CR output channels,\n",
    "#       where R is the expansion ratio (expansion_ratio)\n",
    "# \n",
    "\n",
    "class ExpansionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, expansion_ratio, kernel_size, stride, padding):\n",
    "        super(ExpansionLayer, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, in_channels * expansion_ratio, \n",
    "                              kernel_size, stride=stride, padding=padding, \n",
    "                              groups=in_channels)\n",
    "        self.norm = nn.GroupNorm(in_channels, in_channels)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "# Compression layer:\n",
    "# 1. 1×1×1 kernel and and C output channels performing channel-wise \n",
    "#       compression of the feature maps.\n",
    "# 2. It can have 2xC or 0.5xC\n",
    "class CompressionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CompressionLayer, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, expansion_ratio, out_channels, padding):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        stride = 2\n",
    "        if in_channels == out_channels: stride = 1\n",
    "        self.sampling_ratio = out_channels/in_channels\n",
    "        \n",
    "        self.depthwise_conv = DepthwiseConv3d(in_channels, kernel_size, padding)\n",
    "        self.expansion_layer = ExpansionLayer(in_channels, expansion_ratio, 1 , stride, padding)\n",
    "        self.compression_layer = CompressionLayer(in_channels * expansion_ratio, out_channels)\n",
    "        \n",
    "        # Layer only for sampling ratio not 1 \n",
    "        self.conv_transpose = nn.Conv3d(in_channels, in_channels * self.sampling_ratio, \n",
    "                              kernel_size = 1, stride=2, groups=in_channels)\n",
    "\n",
    "        # self.block_expansion_ratio = out_channels/in_channels # It can have 2xC or 0.5xC\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise_conv(x)\n",
    "        out = self.expansion_layer(out)\n",
    "        out = self.compression_layer(out)\n",
    "        if self.sampling_ratio != 1:\n",
    "            return out + self.conv_transpose(x)\n",
    "        return out + x #Residual block (is it just sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel size 5x5x5 - most effective\n",
    "# Expansion Ratios: \n",
    "# R1 = R9 = 3\n",
    "# R2 = R8 = 4\n",
    "# R3-R7 = 8\n",
    "\n",
    "# Number of blocks\n",
    "# B1 = B9 = 3\n",
    "# B2 = B8 = 4\n",
    "# B3−7 = 8 \n",
    "\n",
    "#stride = 1 if in == out, and 2 if in != out\n",
    "\n",
    "# MedNeXt-B (5 × 5 × 5) + UpKern 84.23 87.06 89.38 92.36\n",
    "\n",
    "kernel_size = 5\n",
    "\n",
    "#B1 and B9 \n",
    "class MedNeXtBlock_x3(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MedNeXtBlock_x3, self).__init__()\n",
    "        R1 = 3 # Expansion Ratio \n",
    "        self.l1 = ResidualLayer(in_channels, kernel_size, R1, in_channels, (2, 2, 2))\n",
    "        self.l2 = ResidualLayer(in_channels, kernel_size, R1, in_channels, (2, 2, 2))\n",
    "        self.l3 = ResidualLayer(in_channels, kernel_size, R1, in_channels, (2, 2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1 (x)\n",
    "        out = self.l2 (out)\n",
    "        out = self.l3 (out)\n",
    "        return out\n",
    "        \n",
    "#B2 and B8 \n",
    "class MedNeXtBlock_x4(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MedNeXtBlock_x4, self).__init__()\n",
    "        R2 = 4 # Expansion Ratio \n",
    "        self.l1 = ResidualLayer(in_channels, kernel_size, R2, in_channels, (2, 2, 2))\n",
    "        self.l2 = ResidualLayer(in_channels, kernel_size, R2, in_channels, (2, 2, 2))\n",
    "        self.l3 = ResidualLayer(in_channels, kernel_size, R2, in_channels, (2, 2, 2))\n",
    "        self.l4 = ResidualLayer(in_channels, kernel_size, R2, in_channels, (2, 2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1 (x)\n",
    "        out = self.l2 (out)\n",
    "        out = self.l3 (out)\n",
    "        out = self.l4 (out)\n",
    "        return out\n",
    "    \n",
    "#B3-B7\n",
    "class MedNeXtBlock_x8(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MedNeXtBlock_x8, self).__init__()\n",
    "        R3 = 8 # Expansion Ratio \n",
    "        self.l1 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "        self.l2 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "        self.l3 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "        self.l4 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "        self.l5 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "        self.l6 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "        self.l7 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "        self.l8 = ResidualLayer(in_channels, kernel_size, R3, in_channels, (2, 2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1 (x)\n",
    "        out = self.l2 (out)\n",
    "        out = self.l3 (out)\n",
    "        out = self.l4 (out)\n",
    "        out = self.l5 (out)\n",
    "        out = self.l6 (out)\n",
    "        out = self.l7 (out)\n",
    "        out = self.l8 (out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_11620/1260952322.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\alist\\AppData\\Local\\Temp/ipykernel_11620/1260952322.py\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    def forward(self, x):\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Expansion Ratios: \n",
    "# R1 = R9 = 3\n",
    "# R2 = R8 = 4\n",
    "# R3-R7 = 8\n",
    "\n",
    "# Number of blocks\n",
    "# B1 = B9 = 3\n",
    "# B2 = B8 = 4\n",
    "# B3−7 = 8 \n",
    "\n",
    "class MedNeXt(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MedNeXt, self).__init__()\n",
    "        # Expansion Ratios\n",
    "        R1 = 3 # R9\n",
    "        R2 = 4 # R8\n",
    "        R3 = 8 # R3-R7\n",
    "        C = in_channels\n",
    "\n",
    "        # Encoder\n",
    "        self.l1 = MedNeXtBlock_x3 (C)\n",
    "        self.l2 = ResidualLayer(C, kernel_size, R2, C*2, (2, 2, 2)) # Down 2x\n",
    "        self.l3 = MedNeXtBlock_x4 (C*2)\n",
    "        self.l4 = ResidualLayer(C*2, kernel_size, R3, C*4, (2, 2, 2)) # Down 2x\n",
    "        self.l5 = MedNeXtBlock_x8 (C*4)\n",
    "        self.l6 = ResidualLayer(C*4, kernel_size, R3, C*8, (2, 2, 2)) # Down 2x\n",
    "        self.l7 = MedNeXtBlock_x8 (C*8)\n",
    "        self.l8 = ResidualLayer(C*8, kernel_size, R3, C*16, (2, 2, 2)) # Down 2x\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualLayer(C*16, kernel_size, R3, C*16, (2, 2, 2))\n",
    "\n",
    "        # Decoder\n",
    "        self.l9 = ResidualLayer(C*16, kernel_size, R3, C*8, (2, 2, 2)) # Up 2x\n",
    "        self.l10 = MedNeXtBlock_x8 (C*8)\n",
    "        self.l11 = ResidualLayer(C*8, kernel_size, R3, C*4, (2, 2, 2)) # Up 2x\n",
    "        self.l12 = MedNeXtBlock_x8 (C*4)\n",
    "        self.l11 = ResidualLayer(C*4, kernel_size, R3, C*2, (2, 2, 2)) # Up 2x\n",
    "        self.l12 = MedNeXtBlock_x4 (C*2)\n",
    "        self.l11 = ResidualLayer(C*2, kernel_size, R2, C*1, (2, 2, 2)) # Up 2x\n",
    "        self.l12 = MedNeXtBlock_x3 (C)\n",
    "\n",
    "    def forward(self, x):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data: tensor([[[ 22,  24,  24,  ...,  96,  94,  93],\n",
      "         [ 23,  24,  24,  ...,  97,  94,  92],\n",
      "         [ 24,  24,  23,  ...,  99,  96,  94],\n",
      "         ...,\n",
      "         [ 49,  50,  48,  ..., 119, 119, 119],\n",
      "         [ 50,  52,  53,  ..., 123, 124, 123],\n",
      "         [ 52,  53,  54,  ..., 129, 128, 127]]], dtype=torch.uint8)\n",
      "Is image a PyTorch Tensor: True\n",
      "Type of Image: <class 'torch.Tensor'>\n",
      "torch.Size([1, 1858, 2090])\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataset \n",
    "\n",
    "# read a JPEG image\n",
    "img = read_image('.\\\\Datasets\\\\chest_xray\\\\train\\\\NORMAL\\\\IM-0115-0001.jpeg')\n",
    "\n",
    "# display the image properties\n",
    "print(\"Image data:\", img)\n",
    "\n",
    "# check if input image is a PyTorch tensor\n",
    "print(\"Is image a PyTorch Tensor:\", torch.is_tensor(img))\n",
    "print(\"Type of Image:\", type(img))\n",
    "\n",
    "# size of the image\n",
    "print(img.size())\n",
    "\n",
    "# convert the torch tensor to PIL image\n",
    "img = transforms.ToPILImage()(img)\n",
    "\n",
    "# display the image\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"\"\"Implementation of the gelu activation function.\"\"\"\n",
    "    return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseConv2d, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n",
    "                                        padding=padding, groups=in_channels)\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.pointwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pointwise_conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, \n",
    "                                 download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, \n",
    "                                download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
