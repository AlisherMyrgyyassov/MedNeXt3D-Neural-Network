{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel size k x k x k\n",
    "# 1. Depthwise Convolution with kernel size k × k × k\n",
    "# 2. Normalization, with C output channels\n",
    "#       We use channel-wise GroupNorm for stability with small\n",
    "#       batches, instead of the original LayerNorm\n",
    "class DepthwiseConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, padding=0, bias=False):\n",
    "        super(DepthwiseConv3d, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv3d(in_channels, in_channels, \n",
    "                                        kernel_size=kernel_size, padding=padding, \n",
    "                                        groups=in_channels, bias=bias)\n",
    "        self.norm = nn.GroupNorm(num_groups=in_channels, num_channels=in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise_conv(x)\n",
    "        out = self.norm(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Expansion layer contains:\n",
    "# 1. An overcomplete Convolution Layer with CR output channels,\n",
    "#       where R is the expansion ratio (expansion_ratio)\n",
    "# \n",
    "\n",
    "class ExpansionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, expansion_ratio, kernel_size, stride, padding):\n",
    "        super(ExpansionLayer, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, in_channels * expansion_ratio, \n",
    "                              kernel_size, stride=stride, padding=padding, \n",
    "                              groups=in_channels)\n",
    "        self.norm = nn.GroupNorm(in_channels, in_channels)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "    \n",
    "# Compression layer:\n",
    "# 1. 1×1×1 kernel and and C output channels performing channel-wise \n",
    "#       compression of the feature maps.\n",
    "# 2. It can have 2xC or 0.5xC\n",
    "class CompressionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CompressionLayer, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, expansion_ratio, out_channels, stride, padding):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.depthwise_conv = DepthwiseConv3d(in_channels, kernel_size, padding)\n",
    "        self.expansion_layer = ExpansionLayer(in_channels, expansion_ratio, kernel_size, stride, padding)\n",
    "        self.compression_layer = CompressionLayer(in_channels * expansion_ratio, out_channels)\n",
    "\n",
    "        # self.block_expansion_ratio = out_channels/in_channels # It can have 2xC or 0.5xC\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise_conv(x)\n",
    "        out = self.expansion_layer(out)\n",
    "        out = self.compression_layer(out)\n",
    "        return out + x #Residual block (is it just sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data: tensor([[[ 22,  24,  24,  ...,  96,  94,  93],\n",
      "         [ 23,  24,  24,  ...,  97,  94,  92],\n",
      "         [ 24,  24,  23,  ...,  99,  96,  94],\n",
      "         ...,\n",
      "         [ 49,  50,  48,  ..., 119, 119, 119],\n",
      "         [ 50,  52,  53,  ..., 123, 124, 123],\n",
      "         [ 52,  53,  54,  ..., 129, 128, 127]]], dtype=torch.uint8)\n",
      "Is image a PyTorch Tensor: True\n",
      "Type of Image: <class 'torch.Tensor'>\n",
      "torch.Size([1, 1858, 2090])\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataset \n",
    "\n",
    "# read a JPEG image\n",
    "img = read_image('.\\\\Datasets\\\\chest_xray\\\\train\\\\NORMAL\\\\IM-0115-0001.jpeg')\n",
    "\n",
    "# display the image properties\n",
    "print(\"Image data:\", img)\n",
    "\n",
    "# check if input image is a PyTorch tensor\n",
    "print(\"Is image a PyTorch Tensor:\", torch.is_tensor(img))\n",
    "print(\"Type of Image:\", type(img))\n",
    "\n",
    "# size of the image\n",
    "print(img.size())\n",
    "\n",
    "# convert the torch tensor to PIL image\n",
    "img = transforms.ToPILImage()(img)\n",
    "\n",
    "# display the image\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    \"\"\"Implementation of the gelu activation function.\"\"\"\n",
    "    return x * torch.sigmoid(1.702 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseConv2d, self).__init__()\n",
    "        self.depthwise_conv = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n",
    "                                        padding=padding, groups=in_channels)\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.pointwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pointwise_conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, \n",
    "                                 download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, \n",
    "                                download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
